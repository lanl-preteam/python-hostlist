#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# rewrite of dshbak using python-hostlist

__version__ = "#VERSION#"

# Copyright (C) 2010 Mattias Slabanja <slabanja@chalmers.se>
#               
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
# 02110-1301, USA.

import sys
import optparse
import re

from hostlist import collect_hostlist, expand_hostlist, __version__ as library_version
from difflib import unified_diff, SequenceMatcher 
from itertools import count

def scan():
    """Scan stdin, store lines by host, and return it all in a
    dictionary indexed by host.

    Input lines are expected to be on the format
    "<hostname>:<rest of line>". Lines not matching that format
    are added to the dictionary using None as key.

    The linesplit-re is designed to match the original dshbak behavior. 
    """

    linesplitter = re.compile(r'^ *([A-Za-z0-9.-]+) *: ?(.*)$')
    text_dict = {}

    for line in sys.stdin:
        match = linesplitter.match(line)
        if match:
            host, hostline = match.groups()
        else:
            # The linesplitter regexp did NOT match.
            # This line will be added to text_dict[None]
            host = None
            hostline = line.rstrip('\n')

        if host in text_dict:
            # The groups in the linesplitter regexp does not include the trailing '\n'
            text_dict[host] += "\n" + hostline
        else:
            text_dict[host] = hostline

    return text_dict

def collect(text_dict):
    """Collect hosts having identical output.

    Return a list of (host set, text) tuples."""

    reverse_dict = {}
    for host, text in text_dict.iteritems():
        if text in reverse_dict:
            reverse_dict[text].add(host)
        else:
            reverse_dict[text] = set((host,))

    return [(host_set, text) for text, host_set in reverse_dict.iteritems()]

def output(host_set_or_str, text, count_hosts = False):
    """Prepend the output with a hostname framed with horizontal lines."""
    hline = '-' * 16
    if isinstance(host_set_or_str, str):
        header = host_set_or_str # for the benefit of the garbage header
    else:
        header = collect_hostlist(host_set_or_str)
        if count_hosts:
            header = "%d: %s" % (len(host_set_or_str),  header)
    print hline
    print header
    print hline
    print text


def in_red(s):
    return '\033[91m' + s + '\033[0m'

class Collector:
    """Collect closely matching texts, find similarities and differences

    Depends on SequenceMatcher. 
    Texts being similar enough when doing a line-per-line comparison
    to a reference text can be added using the try_add_text method.
    When texts of interest has been added, calling the process method
    will sort out which parts are identical (per line intersection 
    of all matches between reference and succeeding texts)
    and will store the individual differences.
    The heavy part of the processing is done by
    SequenceMatcher.get_matching_blocks called from try_add_text.
    """
    def __init__(self, ref_text, tag=None):
        ref_lines = ref_text.split('\n')
        self.N = len(ref_lines)
        self._matchers = [SequenceMatcher(None, L, L) for L in ref_lines]
        self._lmb_pairs = [[] for i in range(self.N)]
        self._tags = []
        self._tag_counter = count(1)

        self._reset_processing_result()
        self._add_lines(ref_lines)
        self._push_tag_name(tag)

    def try_add_text(self, text, tag=None):
        lines = text.split('\n')
        if len(lines) != self.N:
            return False

        self._update_seq1(lines)

        ratio = (1.0/self.N) * sum([mat.quick_ratio() for mat in self._matchers])
        if ratio < 0.50:
            return False

        self._reset_processing_result()
        self._add_lines(lines)
        self._push_tag_name(tag)
        return True

    def process(self):
        for i in range(self.N):
            self._process_line(i)

        self.text = '\n'.join(self._text_lines)
        print self.text

    def _update_seq1(self, lines):
        for L, mat in zip(lines, self._matchers):
            mat.set_seq1(L)

    def _reset_processing_result(self):
        self.text = None
        self._text_lines = [''] * self.N
        self._diff_counter = count(1)

    def _add_lines(self, lines):
        # matchers seq1 must already be updated
        for lmbs, L, mat in zip(self._lmb_pairs, lines, self._matchers):
            lmbs.append((L, mat.get_matching_blocks())) #This is what's taking time
        
    def _push_tag_name(self, tag=None):
        if tag is None:
            self._tags.append('text%i' % self._tag_counter.next())
        else:
            self._tags.append(tag)
            
    def _process_line(self, line_i):
        lmbs = self._lmb_pairs[line_i]
        ref_L, _ = lmbs[0]
        ref_L_N = len(ref_L)
        part_mask = [1] * (ref_L_N+1) #Extra 1 to indicate trailing diff
        for _, mb in lmbs[1:]:
            ipn = jpn = 0
            for i, j, n in mb:
                if ((i != 0 or j != 0) and
                    (jpn != j or ipn != i)):
                    #There is a diff, update the partion mask
                    for jind in range(jpn, j):
                        part_mask[jind] = False
                    for jind in range(j, ref_L_N+1):
                        if part_mask[jind]:
                            part_mask[jind] += 1
                jpn = j + n
                ipn = i + n
        part_mask, end_part = part_mask[:-1], part_mask[-1]

        # collect combined non- and minimal- matching blocks between
        # the reference line and all other lines.
        nm_mb = []
        opi = 0
        op = 1
        
        for i in range(0, ref_L_N):
            if part_mask[i] is False:
                if op is False:
                    # Continue along non-matching block
                    continue
                else:
                    # from matching to non-matching block
                    nm_mb.append(('m', opi, i-opi))
            else:
                if part_mask[i] == op:
                    # Continue along matching block
                    continue
                elif op is False:
                    # from non-matching to matching block
                    nm_mb.append(('n', opi, i-opi))
                else:
                    # between matching (via 0-length non-matching)
                    nm_mb.append(('m', opi, i-opi))
                    nm_mb.append(('n', i, 0))
            op = part_mask[i]
            opi = i                    

        if op is False:
            nm_mb.append(('n', opi, ref_L_N-opi))
        else:
            nm_mb.append(('m', opi, ref_L_N-opi))
            if op != end_part:
                nm_mb.append(('n', ref_L_N, 0))

        if len(nm_mb) == 1:
            #No non-matching-blocks, hence all lines are identical
            self._text_lines[line_i] = ref_L
            return

        line = ''
        for t, i, n in nm_mb:
            if t == 'm':
                line += ref_L[i:i+n]
            elif t == 'n':
                line += in_red('[DIFF%i]' % self._diff_counter.next())
                for L, mb in lmbs:
                    pass
        self._text_lines[line_i] = line
    
        

# MAIN

op = optparse.OptionParser(usage="usage: %prog [OPTION]...",
                           add_help_option = False)

op.add_option("-c", "--collect", action="store_true",
              help="Collect identical output.")
op.add_option("-C", "--crazy-collect", action="store_true",
              help="Collect similar output.")

op.add_option("-n", "--count", action="store_true",
              help="Show the number of hosts in the header.")

op.add_option("-d", "--unified-diff", action="store_true",
              help="Print the most frequent output in its full form, "
              "and all other outputs as unified diffs "
              "relative the most frequent output. This option implies --collect.")

op.add_option("-g", "--with-garbage", action="store_true",
              help="Also collect and print input not conforming to the "
              ' "host : output"-format. '
              "Garbage output will be presented separated from host output.")

op.add_option("-h", "--help", action="help", help="Show help")
op.add_option("--version",
              action="store_true",
              help="Show version")

(opts, args) = op.parse_args()

if opts.version:
    print "Version %s (library version %s)" % (__version__, library_version)
    sys.exit()

try:
    text_dict = scan()

    if opts.with_garbage and None in text_dict:
        # The user wants to see garbage-output, and it is non-empty.
        # Print it before the host output regardless of diff/normal mode.
        output('NON-FORMATTED OUTPUT', text_dict[None])
    # Remove garbage lines from text_dict
    text_dict.pop(None,None)

    if opts.unified_diff:
        # "Unified diff mode", print the most abundant output, O, in full, and all
        # other outputs as a unified diff relative O.

        hosts_text_list = collect(text_dict)

        # Sort in descending order of the number of hosts
        hosts_text_list.sort(key = lambda x: -len(x[0]))

        if len(hosts_text_list) == 0:
            sys.exit()

        # The most abundant output
        ref_host_set, ref_text = hosts_text_list.pop(0)
        ref_hostlist = collect_hostlist(ref_host_set)

        # Split into lines for use with difflib.
        ref_lines = ref_text.split('\n')

        output(ref_host_set, ref_text, opts.count)

        for host_set, text in hosts_text_list:
            output(host_set,
                   '\n'.join(unified_diff(ref_lines,
                                          text.split('\n'),
                                          fromfile=ref_hostlist,
                                          tofile=collect_hostlist(host_set),
                                          lineterm='')),
                   opts.count)

    elif opts.crazy_collect:

        ref_host, ref_text = text_dict.popitem()
        c = Collector(ref_text)
        for h, t in text_dict.iteritems():
            if c.try_add_text(t):
                print "Added ", h
            else:
                print "Ignored ", h
        c.process()

    else:
        # "Normal" mode, just print the output

        if opts.collect:
            hosts_text_list = collect(text_dict)
        else:
            hosts_text_list = [(set((n,)), l) for n,l in text_dict.iteritems()]

        # Sort in descending order of the number of hosts
        hosts_text_list.sort(key = lambda x: -len(x[0]))

        for host_set, text in hosts_text_list:
            output(host_set, text, opts.count)

except KeyboardInterrupt:
    sys.exit()
